{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "authorship_tag": "ABX9TyMYgGMee1g+I4qTgGU/bQHV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaon11579/2022-spring-NLP-/blob/main/July%2030_topic%20clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/"
      ],
      "metadata": {
        "id": "7_GhRumYPT6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA in Python – How to grid search best topic models?"
      ],
      "metadata": {
        "id": "Pu4bEnrLwOF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries for visualization\n",
        "!pip install pyLDAvis\n",
        "!pip install pyLDAvis.gensim_models\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOOZ8txgxF4Q",
        "outputId": "15bb979e-7c16-4838-964b-bbe17e0c4991"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.3)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.17)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyLDAvis.gensim_models (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pyLDAvis.gensim_models\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zNgpN0CBwFzz"
      },
      "outputs": [],
      "source": [
        "# Run in terminal or command prompt\n",
        "# python3 -m spacy download en\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, nltk, spacy, gensim\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pprint import pprint\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dataset\n",
        "df = pd.read_fwf(r'/bin/cleaned_file.txt', header=None)\n",
        "df = pd.DataFrame(df)\n",
        "#df = pd.read_json('/content/.config/cleaned_file.txt')\n",
        "#print(df.target_names.unique())\n",
        "df.head(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "1xPHl8GUxNhR",
        "outputId": "c2534738-c36f-4829-88a0-410b9ebec0d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    0\n",
              "0        IndustrialMarketingManagement89(2020)630–641\n",
              "1           Contents lists available at ScienceDirect\n",
              "2                     Industrial Marketing Management\n",
              "3   journal homepage: www.elsevier.com/locate/indm...\n",
              "4                                      Research paper\n",
              "5   B2B brands on Twitter: Engaging rs with a vary...\n",
              "6                 objectives, strategies, and tactics\n",
              "7   Mari Juntunenᵃ,⁎, Elvira Ismagilovaᵇ, Eeva-Lii...\n",
              "8   ᵃ Department of Marketing, Management and Inte...\n",
              "9              of Oulu, P.O. Box 4600, 90014, Finland\n",
              "10  ᵇ School of Management, University of Bradford...\n",
              "11  ᶜ Department of Marketing, Management and Inte...\n",
              "12                              A R T I C L E I N F O\n",
              "13                                          Keywords:\n",
              "14                                    B2B advertising"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f0df06b-ea2b-401a-9ecc-f524c7691b1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IndustrialMarketingManagement89(2020)630–641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Contents lists available at ScienceDirect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Industrial Marketing Management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>journal homepage: www.elsevier.com/locate/indm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Research paper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>B2B brands on Twitter: Engaging rs with a vary...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>objectives, strategies, and tactics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Mari Juntunenᵃ,⁎, Elvira Ismagilovaᵇ, Eeva-Lii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ᵃ Department of Marketing, Management and Inte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>of Oulu, P.O. Box 4600, 90014, Finland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ᵇ School of Management, University of Bradford...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ᶜ Department of Marketing, Management and Inte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>A R T I C L E I N F O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Keywords:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>B2B advertising</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f0df06b-ea2b-401a-9ecc-f524c7691b1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f0df06b-ea2b-401a-9ecc-f524c7691b1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f0df06b-ea2b-401a-9ecc-f524c7691b1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "zAdqF2XH-kld"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to list\n",
        "df = df.values.tolist()\n",
        "\n",
        "# Remove Emails\n",
        "#df = [re.sub('\\S*@\\S*\\s?', '', str(df)) for sent in df]\n",
        "\n",
        "# Remove new line characters\n",
        "#df = [re.sub('\\s+', ' ', sent) for sent in df]\n",
        "\n",
        "# Remove distracting single quotes\n",
        "#df = [re.sub(\"\\'\", \"\", sent) for sent in df]\n",
        "\n",
        "pprint(df[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqx2fBnN0vyk",
        "outputId": "1ba2247b-0543-4741-8227-564340b988c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['IndustrialMarketingManagement89(2020)630–641']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pprint(df[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cErn-E4XTYpc",
        "outputId": "602c71ea-648f-4885-fed4-bc394529ef67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretty printing has been turned OFF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(df))\n",
        "\n",
        "print(data_words[:10])"
      ],
      "metadata": {
        "id": "7_RPJEHBCLNy",
        "outputId": "dfbbf813-cc7e-4bad-a4dc-6b5ffb40086c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[], ['contents', 'lists', 'available', 'at', 'sciencedirect'], ['industrial', 'marketing', 'management'], ['journal', 'homepage', 'www', 'elsevier', 'com', 'locate', 'indmarman'], ['research', 'paper'], ['brands', 'on', 'twitter', 'engaging', 'rs', 'with', 'varying', 'combination', 'of', 'social', 'media', 'content'], ['objectives', 'strategies', 'and', 'tactics'], ['mari', 'juntunenᵃ', 'elvira', 'ismagilovaᵇ', 'eeva', 'liisa', 'oikarinenᶜ'], ['department', 'of', 'marketing', 'management', 'and', 'international', 'business', 'oulu', 'business', 'school', 'university'], ['of', 'oulu', 'box', 'finland']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Lemmatization\n",
        "\n",
        " Lemmatization is a process where we convert words to its root word.\n",
        "For example: ‘Studying’ becomes ‘Study’, ‘Meeting becomes ‘Meet’, ‘Better’ and ‘Best’ becomes ‘Good’.\n",
        "\n",
        "The advantage of this is, we get to reduce the total number of unique words in the dictionary.\n",
        "\n",
        "As a result, the number of columns in the document-word matrix (created by CountVectorizer in the next step) will be denser with lesser columns.\n",
        "\n",
        "You can expect better topics to be generated in the end."
      ],
      "metadata": {
        "id": "Q__r6QJFeviN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
        "    return texts_out\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# Run in terminal: python3 -m spacy download en\n",
        "#nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
        "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:10])"
      ],
      "metadata": {
        "id": "nXPGOJ6lV2Yc",
        "outputId": "5081a508-20f9-42ca-dcd7-4848ec7651b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'content list available sciencedirect', 'industrial marketing management', 'homepage www elsevi com locate indmarman', 'research paper', 'brand twitter engage vary combination social medium content', 'objective strategy tactic', '', 'marketing management international business oulu university', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create the Document-Word matrix"
      ],
      "metadata": {
        "id": "n6Ck9LRCf5tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(analyzer='word',       \n",
        "                             min_df=10,                        # minimum reqd occurences of a word \n",
        "                             stop_words='english',             # remove stop words\n",
        "                             lowercase=True,                   # convert all words to lowercase\n",
        "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
        "                             # max_features=50000,             # max number of uniq words\n",
        "                            )\n",
        "\n",
        "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
      ],
      "metadata": {
        "id": "-N627OWCfvBD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Check the Sparsicity"
      ],
      "metadata": {
        "id": "_wfUgl411Dn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Materialize the sparse data\n",
        "data_dense = data_vectorized.todense()\n",
        "\n",
        "# Compute Sparsicity = Percentage of Non-Zero cells\n",
        "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
      ],
      "metadata": {
        "id": "DbBTGWBL1BKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. # Build LDA model with sklearn\n",
        "\n",
        "Everything is ready to build a Latent Dirichlet Allocation (LDA) model. Let’s initialise one and call fit_transform() to build the LDA model.\n",
        "\n",
        "For this example, I have set the n_topics as 20 based on prior knowledge about the dataset. Later we will find the optimal number using grid search."
      ],
      "metadata": {
        "id": "IkjYFTPB1O9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LDA Model\n",
        "lda_model = LatentDirichletAllocation(n_components=20,               # Number of topics\n",
        "                                      max_iter=10,               # Max learning iterations\n",
        "                                      learning_method='online',   \n",
        "                                      random_state=100,          # Random state\n",
        "                                      batch_size=128,            # n docs in each learning iter\n",
        "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
        "                                      n_jobs = 1,\n",
        "                                      )              # Use all available CPUs\n",
        "                                      \n",
        "lda_output = lda_model.fit_transform(data_vectorized)\n",
        "\n",
        "print(lda_model)  # Model attributes"
      ],
      "metadata": {
        "id": "lDwGGkc71LLw",
        "outputId": "35822303-f64f-449c-8590-6bb423b8048a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentDirichletAllocation(learning_method='online', n_components=20, n_jobs=1,\n",
            "                          random_state=100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
        "             evaluate_every=-1, learning_decay=0.7,\n",
        "             learning_method='online', learning_offset=10.0,\n",
        "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
        "             n_components=20, n_jobs=-1, perp_tol=0.1,\n",
        "             random_state=100, topic_word_prior=None,\n",
        "             total_samples=1000000.0, verbose=0)"
      ],
      "metadata": {
        "id": "35o9tJaaO6Vr",
        "outputId": "b522a44e-2be6-4624-dfdc-c7ddd068cee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(learning_method='online', n_components=20, n_jobs=-1,\n",
              "                          random_state=100)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Diagnose model performance with perplexity and log-likelihood"
      ],
      "metadata": {
        "id": "4r8Q25bfPBhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Log Likelyhood: Higher the better\n",
        "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
        "\n",
        "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
        "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
        "\n",
        "# See model parameters\n",
        "pprint(lda_model.get_params())"
      ],
      "metadata": {
        "id": "KmdWRtUqO-rE",
        "outputId": "18c831c5-3e98-46d1-a7d9-992e6ae4a09c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Likelihood:  -46369135.923838206\n",
            "Perplexity:  4183.609862729518\n",
            "{'batch_size': 128,\n",
            " 'doc_topic_prior': None,\n",
            " 'evaluate_every': -1,\n",
            " 'learning_decay': 0.7,\n",
            " 'learning_method': 'online',\n",
            " 'learning_offset': 10.0,\n",
            " 'max_doc_update_iter': 100,\n",
            " 'max_iter': 10,\n",
            " 'mean_change_tol': 0.001,\n",
            " 'n_components': 20,\n",
            " 'n_jobs': 1,\n",
            " 'perp_tol': 0.1,\n",
            " 'random_state': 100,\n",
            " 'topic_word_prior': None,\n",
            " 'total_samples': 1000000.0,\n",
            " 'verbose': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. How to GridSearch the best LDA model?\n",
        ".\n",
        "The most important tuning parameter for LDA models is n_components (number of topics). In addition, I am going to search learning_decay (which controls the learning rate) as well.\n",
        "\n",
        "Besides these, other possible search params could be learning_offset (downweigh early iterations. Should be > 1) and max_iter. These could be worth experimenting if you have enough computing resources.\n",
        "\n",
        "Be warned, the grid search constructs multiple LDA models for all possible combinations of param values in the param_grid dict. So, this process can consume a lot of time and resources."
      ],
      "metadata": {
        "id": "eYFH2Wr5PSXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Search Param\n",
        "search_params = {'n_components': [10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}\n",
        "\n",
        "# Init the Model\n",
        "lda = LatentDirichletAllocation()\n",
        "\n",
        "# Init Grid Search Class\n",
        "model = GridSearchCV(lda, param_grid=search_params)\n",
        "\n",
        "# Do the Grid Search\n",
        "model.fit(data_vectorized)"
      ],
      "metadata": {
        "id": "rUsTkHhgPIBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/darenr/scikit-optimize"
      ],
      "metadata": {
        "id": "a99mV6DwSTpw",
        "outputId": "db0802d1-a8a0-4c69-c910-e4a05e865dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/darenr/scikit-optimize\n",
            "  Cloning https://github.com/darenr/scikit-optimize to /tmp/pip-req-build-gs6jrw8_\n",
            "  Running command git clone -q https://github.com/darenr/scikit-optimize /tmp/pip-req-build-gs6jrw8_\n",
            "Collecting pyaml\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.6+19.g180d6be) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.6+19.g180d6be) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.6+19.g180d6be) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->scikit-optimize==0.6+19.g180d6be) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->scikit-optimize==0.6+19.g180d6be) (1.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml->scikit-optimize==0.6+19.g180d6be) (3.13)\n",
            "Building wheels for collected packages: scikit-optimize\n",
            "  Building wheel for scikit-optimize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-optimize: filename=scikit_optimize-0.6+19.g180d6be-py2.py3-none-any.whl size=75418 sha256=fad3c6e31f5947b1201c51306c7a3f0ac6a9eadc8ea898078ed2c747d099d3b5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xdlr8d_s/wheels/11/4c/bf/aa91b51947ed5367f98d5a68c59afd45a275b85e9fc4827007\n",
            "Successfully built scikit-optimize\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.6+19.g180d6be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GridSearchCV(cv=None, error_score='raise',\n",
        "       estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
        "             evaluate_every=-1, learning_decay=0.7, learning_method='batch',\n",
        "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
        "             mean_change_tol=0.001, n_components=10, n_jobs=1,\n",
        "             perp_tol=0.1, random_state=None,\n",
        "             topic_word_prior=None, total_samples=1000000.0, verbose=0),\n",
        "       fit_params=None, iid=True, n_jobs=1,\n",
        "       param_grid={'n_components': [10, 15, 20, 25, 30], 'learning_decay': [0.5, 0.7, 0.9]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
        "       scoring=None, verbose=0)"
      ],
      "metadata": {
        "id": "o8QSMLpkPl_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. How to see the best topic model and its parameters?"
      ],
      "metadata": {
        "id": "BjPmOUTUPn09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Model\n",
        "best_lda_model = model.best_estimator_\n",
        "\n",
        "# Model Parameters\n",
        "print(\"Best Model's Params: \", model.best_params_)\n",
        "\n",
        "# Log Likelihood Score\n",
        "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
        "\n",
        "# Perplexity\n",
        "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
      ],
      "metadata": {
        "id": "KiihYT78PrBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Compare LDA Model Performance Scores"
      ],
      "metadata": {
        "id": "I6i59T0cP2AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Log Likelyhoods from Grid Search Output\n",
        "n_topics = [10, 15, 20, 25, 30]\n",
        "log_likelyhoods_5 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.5]\n",
        "log_likelyhoods_7 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.7]\n",
        "log_likelyhoods_9 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.9]\n",
        "\n",
        "# Show graph\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(n_topics, log_likelyhoods_5, label='0.5')\n",
        "plt.plot(n_topics, log_likelyhoods_7, label='0.7')\n",
        "plt.plot(n_topics, log_likelyhoods_9, label='0.9')\n",
        "plt.title(\"Choosing Optimal LDA Model\")\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Log Likelyhood Scores\")\n",
        "plt.legend(title='Learning decay', loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qKsOpkysPvJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. How to see the dominant topic in each document?"
      ],
      "metadata": {
        "id": "NpYlzOcHQAf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Document - Topic Matrix\n",
        "lda_output = best_lda_model.transform(data_vectorized)\n",
        "\n",
        "# column names\n",
        "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_topics)]\n",
        "\n",
        "# index names\n",
        "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
        "\n",
        "# Make the pandas dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
        "\n",
        "# Get dominant topic for each document\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "\n",
        "# Styling\n",
        "def color_green(val):\n",
        "    color = 'green' if val > .1 else 'black'\n",
        "    return 'color: {col}'.format(col=color)\n",
        "\n",
        "def make_bold(val):\n",
        "    weight = 700 if val > .1 else 400\n",
        "    return 'font-weight: {weight}'.format(weight=weight)\n",
        "\n",
        "# Apply Style\n",
        "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
        "df_document_topics"
      ],
      "metadata": {
        "id": "6prPcdliP8f5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}